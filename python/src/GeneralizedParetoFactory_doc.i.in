%feature("docstring") OT::GeneralizedParetoFactory
"Generalized Pareto factory.

See also
--------
DistributionFactory, GeneralizedPareto

Notes
-----
The following :class:`~openturns.ResourceMap` entries can be used to tweak
the parameters of the optimization solver involved in the different estimators:

- `GeneralizedParetoFactory-DefaultOptimizationAlgorithm`
- `GeneralizedParetoFactory-MaximumEvaluationNumber`
- `GeneralizedParetoFactory-MaximumAbsoluteError`
- `GeneralizedParetoFactory-MaximumRelativeError`
- `GeneralizedParetoFactory-MaximumObjectiveError`
- `GeneralizedParetoFactory-MaximumConstraintError`
"

// ---------------------------------------------------------------------

%feature("docstring") OT::GeneralizedParetoFactory::setOptimizationAlgorithm
"Accessor to the solver.

Parameters
----------
solver : :class:`~openturns.OptimizationAlgorithm`
    The solver used for numerical optimization of the likelihood."

// ---------------------------------------------------------------------

%feature("docstring") OT::GeneralizedParetoFactory::getOptimizationAlgorithm
"Accessor to the solver.

Returns
-------
solver : :class:`~openturns.OptimizationAlgorithm`
    The solver used for numerical optimization of the likelihood."

// ---------------------------------------------------------------------

%feature("docstring") OT::GeneralizedParetoFactory::build
"Build the distribution.


**Available usages**:

    build()

    build(*sample*)

    build(*param*)

Parameters
----------
sample : 2-d sequence of float, of dimension 1
    The sample from which :math:`\vect{\theta} = (\sigma, \xi, u)`
    are estimated.
param : sequence of float
   The parameters of the :class:`~openturns.GeneralizedPareto`.

Returns
-------
dist : :class:`~openturns.Distribution`
    The estimated GPD.

Notes
-----
In the first usage, the default :class:`~openturns.GeneralizedPareto` distribution is built.

In the second usage, the chosen algorithm depends on the size of the sample compared
to the :class:`~openturns.ResourceMap` key `GeneralizedParetoFactory-SmallSize`
(see [matthys2003]_ for the theory):

- If the sample size is less or equal to `GeneralizedParetoFactory-SmallSize` from :class:`~openturns.ResourceMap`, then the method of probability weighted moments is used. If it fails, the method of exponential regression is used.
- Otherwise, the first method tried is the method of exponential regression, then the method of probability weighted moments if the first one fails.

In the third usage, a :class:`~openturns.GeneralizedPareto` distribution corresponding to the given parameters is built."
// ---------------------------------------------------------------------

%feature("docstring") OT::GeneralizedParetoFactory::buildAsGeneralizedPareto
"Build the distribution as a GeneralizedPareto type.


**Available usages**:

    build()

    build(*sample*)

    build(*param*)

Parameters
----------
sample : 2-d sequence of float, of dimension 1
    The sample from which :math:`\vect{\theta} = (\sigma, \xi, u)`
    are estimated.
param : sequence of float,
    A vector of parameters of the :class:`~openturns.GeneralizedPareto`.

Returns
-------
dist : :class:`~openturns.GeneralizedPareto`
    The estimated GPD as a :class:`~openturns.GeneralizedPareto`.
    
    In the first usage, the default GeneralizedPareto distribution is built."

// ---------------------------------------------------------------------

%feature("docstring") OT::GeneralizedParetoFactory::buildMethodOfExponentialRegression
"Build the distribution based on the exponential regression estimator.

Parameters
----------
sample : 2-d sequence of float, of dimension 1
    The sample from which :math:`\vect{\theta} = (\sigma, \xi, u)`
    are estimated.

Returns
-------
dist : :class:`~openturns.GeneralizedPareto`
    The estimated GPD.

Notes
-----
Lets denote:

- :math:`y_{i}=i\log\left(\dfrac{x_{(n-i)}-x_{(1)}}{x_{(n-i-1)}-x_{(1)}}\right)` for :math:`i\in\{1,n-3\}`

Then we estimate :math:`(\hat{\sigma}, \hat{\xi}, \hat{u})`
using:

.. math::
    :label: gpd_exponential_estimator

    \hat{\xi} & = \xi^* \\
    \hat{\sigma} & = \dfrac{2(\overline{x}_n- \hat{u}_n)}{1-2\rho} \\
    \hat{u} & = x_{(1)} - \frac{x_{(1)}}{2 + n}

Where :math:`\xi^*` maximizes:

.. math::
    :label: gpd_xi_relation
    
    \sum_{i=1}^{n-2}\log\left(\dfrac{1-(j/n)^{\xi}}{\xi}\right)-\dfrac{1-(j/n)^{\xi}}{\xi}y_i

under the constraint :math:`-1 \leq \xi \leq 1`."

// ---------------------------------------------------------------------

%feature("docstring") OT::GeneralizedParetoFactory::buildMethodOfProbabilityWeightedMoments
"Build the distribution based on the probability weighted moments estimator.

Parameters
----------
sample : 2-d sequence of float, of dimension 1
    The sample from which :math:`\vect{\theta} = (\sigma, \xi, u)`
    are estimated.

Returns
-------
dist : :class:`~openturns.GeneralizedPareto`
    The estimated GPD.

Notes
-----
Lets denote:

- :math:`\left(x_{(i)}\right)_{i\in\{1,\dots,n\}}` the sample sorted in ascending order
- :math:`m=\dfrac{1}{n}\sum_{i=1}^n\left(1-\dfrac{i-7/20}{n}\right)x_{(i)}`
- :math:`\rho=\dfrac{m}{\overline{x}_n}`

Then we estimate :math:`(\hat{\sigma}, \hat{\xi}, \hat{u})` using:

.. math::
    :label: gpd_probability_weighted_moment_estimator

    \hat{u}_n & = x_{(1)} - \frac{x_{(1)}}{2 + n}\\
    \hat{\xi}_n & = \dfrac{1-4\rho}{1-2\rho} \\
    \hat{\sigma}_n & = \dfrac{2(\overline{x}_n- \hat{u}_n)}{1-2\rho}

This estimator is well-defined only if :math:`\hat{\xi}_n>-1/2`, otherwise the first moment does not exist."

// ---------------------------------------------------------------------

%feature("docstring") OT::GeneralizedParetoFactory::buildMethodOfMoments
"Build the distribution based on the method of moments estimator.

Parameters
----------
sample : 2-d sequence of float, of dimension 1
    The sample from which :math:`\vect{\theta} = (\sigma, \xi, u)`
    are estimated.

Returns
-------
dist : :class:`~openturns.GeneralizedPareto`
    The estimated GPD.

Notes
-----
Lets denote:

- :math:`\displaystyle \overline{x}_n = \frac{1}{n} \sum_{i=1}^n x_i` the empirical
  mean of the sample, 
- :math:`\displaystyle s_n^2 = \frac{1}{n-1} \sum_{i=1}^n (x_i - \overline{x}_n)^2`
  its empirical variance.

Then, we estimate :math:`(\hat{\sigma}_n, \hat{\xi}_n, \hat{u}_n)` using:

.. math::
    :label: gpd_moment_estimator

    \hat{u}_n & = x_{(1)} - \dfrac{x_{(1)}}{2 + n} \\
    \hat{\xi}_n & = -\dfrac{1}{2}\left(\dfrac{(\overline{x}_n - \hat{u}_n)^2}{s_n^2}-1\right) \\
    \hat{\sigma}_n & = \dfrac{(\overline{x}_n- \hat{u}_n)}{2}\left(\dfrac{(\overline{x}_n- \hat{u}_n)^2}{s_n^2}+1\right)

This estimator is well-defined only if :math:`\hat{\xi}>-1/4`, otherwise the second moment does not exist."

// ---------------------------------------------------------------------

%feature("docstring") OT::GeneralizedParetoFactory::drawMeanResidualLife
"Draw the mean residual life plot.


Parameters
----------
sample : 2-d sequence of float, of dimension 1
    The sample drawn from :math:`X`.

Returns
-------
graph : :class:`~openturns.Graph`
    The graph of :math:`u \mapsto m_n(u)` and its :math:`95\%` confidence interval.
    
Notes
-----
This method is complementary to :meth:`drawParameterThresholdStability` as a method of threshold
selection.

Let :math:`X` a random variable defined whose excesses above the threshold :math:`u_0`
follow the Generalized Pareto distribution :math:`GPD(\xi, \sigma_0)`.
The mean of excesses of :math:`X` for :math:`u > u_0` is

.. math::

    \Expect{X-u|X>u} = \frac{\sigma_0+\xi u}{1-\xi}

Hence, for all :math:`u>u_0` :math:`\Expect{X-u|X>u}` is a linear function of :math:`u`.
The threshold :math:`u_0` is the smallest value of :math:`u` from which the curve is linear.

The quantity :math:`\Expect{X-u|X>u}` is estimated by the empirical estimator of the mean:

.. math::

    M_n(u) = \frac{1}{n} \sum_{i=1}^n (X_i - u) 1_{X_i \ge u} = \frac{1}{n} \sum_{i=1}^n X_i 1_{X_i \ge u} - u

The estimator :math:`M_n(u)` is asymptotically normal with mean
:math:`\mu(u) = \Expect{X-u|X>u}` and variance :math:`\mu(u)(1 - \mu(u))/n`.

We denote by :math:`m_n(u)` its realization on the sample drawn from :math:`X`.
The mean and the variance of :math:`M_n(u)` are respectively estimated by :math:`m_n(u)` and :math:`m_n(u)(1-m_n(u))`.

The graph :math:`u \mapsto m_n(u)` is termed the *mean residual life plot*.

The confidence level can be set using the :class:`~openturns.ResourceMap` key
`GeneralizedParetoFactory-MeanResidualLifeConfidenceLevel`
The number of threshold points in the graph can be set with the key
`GeneralizedParetoFactory-MeanResidualLifePointNumber`.
"

// ----------------------------------------------------------------------------

%feature("docstring") OT::GeneralizedParetoFactory::buildMethodOfLikelihoodMaximization
"Estimate the distribution with the maximum likelihood method.

Parameters
----------
sample : 2-d sequence of float
    Sample drawn from :math:`X`.
u : float
    Given threshold value.

Returns
-------
distribution : :class:`~openturns.GeneralizedExtremeValue`
    The estimated distribution of :math:`(\hat{\sigma}, \hat{\xi})`.

Notes
-----
Let :math:`X` be a random variable whose excesses above :math:`u` follow
a GPD parameterized by :math:`\vect{\theta} = (\sigma, \xi)`. We assume
that :math:`u` is known.

Let :math:`(x_1, \dots, x_n)` be a sample drawn from :math:`X`. We define the excesses above :math:`u` by:

.. math::

    z_i = x_i - u

for all :math:`1 \leq i \leq n`. 

The maximum likelihood estimator of :math:`(\sigma, \xi)` maximizes  the log-likelihood defined by:

If :math:`\xi \neq 0`:

.. math::
    :label: llgpdR1

    \ell(\sigma, \xi) = -n \log \sigma - \sum_{i=1}^n  \log \left(1 + \xi \frac{z_i}{\sigma}\right)

defined on :math:`(\sigma, \xi)` such that :math:`1+\xi \left( \frac{z_i - u}{\sigma} \right) > 0` for all :math:`1 \leq i \leq n`.

If :math:`\xi = 0`:

.. math::
    :label: llgpdR2

    \ell(\sigma, \xi) = -n \log \sigma - \sigma^{-1} \sum_{i=1}^n \exp z_i
"

// ----------------------------------------------------------------------------

%feature("docstring") OT::GeneralizedParetoFactory::buildMethodOfLikelihoodMaximizationEstimator
"Estimate the distribution and the parameter distribution with the maximum likelihood method.

Parameters
----------
sample : 2-d sequence of float
    Sample drawn from :math:`X`.
u : float
    Given threshold value.

Returns
-------
result : :class:`~openturns.DistributionFactoryLikelihoodResult`
    The result class.

Notes
-----

Let :math:`X` be a random variable whose excesses above :math:`u` follow
a GPD parameterized by :math:`\vect{\theta} = (\sigma, \xi)`. We assume
that :math:`u` is known.

The estimator :math:`(\hat{\sigma}, \hat{\xi})` is defined using the profile log-likelihood  as detailed in
:meth:`buildMethodOfLikelihoodMaximization`.

The result class produced by the method provides:

- the GPD distribution associated to :math:`(\hat{\sigma}, \hat{\xi}, u)`,
- the asymptotic distribution of :math:`(\hat{\sigma}, \hat{\xi}, u)`."

// ----------------------------------------------------------------------------

%feature("docstring") OT::GeneralizedParetoFactory::buildMethodOfXiProfileLikelihood
"Estimate the distribution with the profile likelihood.

Parameters
----------
sample : 2-d sequence of float
    Sample drawn from :math:`X`.
u : float
    Given threshold value.

Returns
-------
distribution : :class:`~openturns.GeneralizedPareto`
    The estimated GPD.

Notes
-----
Let :math:`X` be a random variable whose excesses above :math:`u` follow
a GPD parameterized by :math:`\vect{\theta} = (\sigma, \xi)`. We assume
that :math:`u` is known.

The estimator :math:`(\hat{\sigma}, \hat{\xi})` is defined using a nested numerical optimization of the log-likelihood:

.. math::

    \ell_p (\xi) = \max_{(\sigma)} \ell (\sigma, \xi, u)

where :math:`\ell (\sigma, \xi, u)` is detailed in equations :eq:`llgpdR1` and :eq:`llgpdR2`.

The estimator is given by:

.. math::

    \hat{\xi} & =  \argmax_{\xi} \ell_p(\xi)\\
    \hat{\sigma} & = \argmax_{\sigma} \ell(\sigma, \hat{\xi}, u)

"

// ----------------------------------------------------------------------------

%feature("docstring") OT::GeneralizedParetoFactory::buildMethodOfXiProfileLikelihoodEstimator
"Estimate the distribution and the parameter distribution with the profile likelihood.


Parameters
----------
sample : 2-d sequence of float
    Sample drawn from :math:`X`.
u : float
    Given threshold value.

Returns
-------
result : :class:`~openturns.ProfileLikelihoodResult`
    The result class.

Notes
-----
Let :math:`X` be a random variable whose excesses above :math:`u` follow
a GPD parameterized by :math:`\vect{\theta} = (\sigma, \xi)`. We assume
that :math:`u` is known.

The estimator :math:`(\hat{\sigma}, \hat{\xi})` is defined in :meth:`buildMethodOfXiProfileLikelihood`.

The result class produced by the method provides:

- the GPD distribution associated to :math:`(\hat{\sigma}, \hat{\xi}, u)`,
- the asymptotic distribution of :math:`(\hat{\sigma}, \hat{\xi}, u)`,
- the profile log-likelihood function :math:`\xi \mapsto \ell_p(\xi)`,
- the optimal profile log-likelihood value :math:`\ell_p(\hat{\xi})`,
- confidence intervals of level :math:`(1-\alpha)` of :math:`\xi`."

// ---------------------------------------------------------------------

%feature("docstring") OT::GeneralizedParetoFactory::drawParameterThresholdStability
"Draw the parameter threshold stability plot.


Parameters
----------
sample : 2-d sequence of float, of dimension 1
    The sample drawn from  :math:`X`.
uRange : :class:`~openturns.Interval`
    The range of the threshold :math:`u: [u_{min}, u_{max}]`.

Returns
-------
graph : :class:`~openturns.Graph`
    The graphs of :math:`u \mapsto \hat{\sigma}^{\ast}` and :math:`u \mapsto \hat{\xi}`.

Notes
-----
This method is complementary to :meth:`drawMeanResidualLife` as a method of threshold
selection.

Let :math:`X` a random variable whose excesses above the threshold :math:`u_0`
follow a Generalized Pareto distribution :math:`GPD(\sigma_0, \xi)`. Then the excesses of
:math:`X` above :math:`u>u_0` also follow a Generalized Pareto distribution
:math:`GPD( \sigma_u, \xi)` where:

.. math::
    :label: sigmau

    \sigma_u = \sigma_0 + \xi (u - u_0)

Hence, if we define the modified scale parameter :math:`\sigma^{\ast}` by:

.. math::

    \sigma^{\ast} = \sigma_u - \xi u

then , by virtue of :eq:`sigmau`, :math:`\sigma^{\ast}` is constant with respect to :math:`u`. 

Consequently, estimates of :math:`\sigma^{\ast}` and :math:`\xi` should be constant (or stable
accounting for sampling variability) above
:math:`u_0` if :math:`u_0` is a valid threshold for excesses to follow a Generalized Pareto
distribution.

The method draws the graphs of :math:`u \mapsto \hat{\sigma}^{\ast}` and
:math:`u \mapsto \hat{\xi}` with the respective :math:`95\%` confidence intervals,
for :math:`u \in [u_{min}, u_{max}]`.
The selected threshold is the lowest value of :math:`u` from which the estimates remain
near-constant.

The confidence level can be set using the :class:`~openturns.ResourceMap` key
`GeneralizedParetoFactory-ThresholdStabilityConfidenceLevel`
The number of threshold points in the graph can be set with the key
`GeneralizedParetoFactory-ThresholdStabilityPointNumber`.
"

// ----------------------------------------------------------------------------

%feature("docstring") OT::GeneralizedParetoFactory::buildCovariates
"Estimate a GPD from covariates.

Parameters
----------
sample : 2-d sequence of float
    Sample drawn from a GPD.
u : float
    The threshold.
covariates : 2-d sequence of float
    Covariates sample.
    A constant column is automatically added if none is not provided.
sigmaIndices : sequence of int, optional
    Indices of covariates considered for parameter :math:`\sigma`.

    By default, an empty sequence, and the index of the constant covariate is added
    if empty or if the covariates do not initially contain a constant column.
xiIndices : sequence of int, optional
    Indices of covariates considered for parameter :math:`\xi`.

    By default, an empty sequence, and the index of the constant covariate is added
    if empty or if the covariates do not initially contain a constant column.
sigmaLink : :class:`~openturns.Function`, optional
    The :math:`h_{\sigma}` function.

    By default, the identity function.
xiLink : :class:`~openturns.Function`, optional
    The :math:`h_{\xi}` function.

    By default, the identity function.
initializationMethod : str, optional
    The initialization method for the optimization problem: *Gumbel* or *Static*.

    The default value depends on the key *GeneralizedExtremeValueFactory-InitializationMethod*.
normalizationMethod : str, optional
    The data normalization method: *CenterReduce*, *MinMax* or *None*.

    The default value depends on the key *GeneralizedExtremeValueFactory-NormalizationMethod*.

Returns
-------
result : :class:`~openturns.CovariatesResult`
    The result class.

Notes
-----
Let :math:`Z_{\vect{y}}` whose excesses above the threshold :math:`u` follow a GPD whose parameters :math:`(\sigma, \xi)` depend on :math:`d` covariates
denoted by :math:`\vect{y} = \Tr{(y_1, \dots, y_d)}`:

.. math::

    Z_{\vect{y}} \sim \mbox{GPD}(\sigma(\vect{y}), \xi(\vect{y}), u)

We assume that the threshold :math:`u` is known.

We denote by :math:`(z_{\vect{y}_1}, \dots, z_{\vect{y}_n})`
the values of :math:`Z_{\vect{y}}` associated to the values of the
covariates :math:`(\vect{y}_1, \dots, \vect{y}_n)`.

For numerical reasons, it is recommended to normalize the covariates. Each covariate :math:`y_k`
has its own normalization: 

.. math::

    \tilde{y}_k = \tau_k(y_k) = \dfrac{y_k-c_k}{d_k}

and with three ways of defining :math:`(c_k,d_k)` of the covariate :math:`y_k`:

- the *CenterReduce* method where :math:`c_k = \dfrac{1}{n} \sum_{i=1}^n y_{k,i}` is the covariate mean
  and :math:`d_k = \sqrt{\dfrac{1}{n} \sum_{i=1}^n (y_{k,i}-c_k)^2}` is the standard deviation of the covariates;
- the *MinMax* method where :math:`c_k = \min_i y_{k,i}` is the min value of the covariate
  :math:`y_k` and :math:`d_k = \max_i y_{k,i}- \min_i y_{k,i}` its range;
- the *None* method where :math:`c_k = 0` and :math:`d_k = 1`: in that case, data are not normalized.


Let :math:`\vect{\theta} = (\sigma, \xi)` be the vector of parameters. Then, :math:`\vect{\theta}` depends on all the :math:`d` covariates
even if each component of :math:`\vect{\theta}` only depends on a subset of the covariates. We
denote by :math:`(y_1^q, \dots, y_{d_q}^q)` the :math:`d_q` covariates involved in the modelling
of the component :math:`\theta_q`.

Each component :math:`\theta_q` can be written as a function of the normalized covariates:

.. math::

    \theta_q(y_1^q, \dots, y_{d_q}^q)  & = h_q\left(\sum_{i=1}^{d_q} \tilde{\beta}_i^q\tilde{y}_i^q \right)

This relation can be written  as a function of the real covariates:

.. math::

    \theta_q(y_1^q, \dots, y_{d_q}^q)  & = h_q\left(\sum_{i=1}^{d_q} \beta_i^q(y_i^q - c_i^q) \right) 

where:

- :math:`h_q: \Rset \mapsto \Rset` is usually referred to as the *inverse-link function* of the
  component :math:`\theta_q`,
- each :math:`\beta_i^{q} \in \Rset`.

To allow one of the parameters to remain constant, i.e. independent of the covariates
(this will generally be the case for the parameter :math:`\xi`, the library systematically
adds the constant covariate to the list speciï¬ed by the user, even if it means duplicating it
if the user has already put it in his list.

The complete vector of parameters is defined by:

.. math::

    \Tr{\vect{b}} & = \Tr{( \Tr{\vect{b}_1}, \dots,  \Tr{\vect{b}_p} )} \in  \Rset^{d_t}\\
    \Tr{\vect{b}_q} & =  (\beta_1^q, \dots, \beta_{d_q}^q)\in \Rset^{d_q}

where :math:`d_t = \sum_{q=1}^p d_q`.

The estimator of  :math:`\vect{\beta}` maximizes  the likelihood of the model which is defined by:

.. math::

    L(\vect{\beta}) = \prod_{i=1}^{n} g(z_{\vect{y}_i};\vect{\theta}(\vect{y}_i)))

where :math:`g(z_{\vect{y}_i};\vect{\theta}(\vect{y}_i))` denotes the GPD density function with
parameters
:math:`\vect{\theta}(\vect{y}_i)` and evaluated at :math:`z_{\vect{y}_i}`.

Then, if none of the :math:`\xi(\vect{y}_i)` is zero, the log-likelihood is defined by:

.. math::

    \ell (\vect{\beta}) = -\sum_{i=1}^{n} \left\{ \log(\sigma(\vect{y}_i)) +
    (1 + 1 / \xi(\vect{y}_i) ) \log\left[ 1+\xi(\vect{y}_i) \left( \frac{z_{\vect{y}_i} -
    \mu(\vect{y}_i)}{\sigma(\vect{y}_i)}\right) \right] + \left[ 1 + \xi(\vect{y}_i)
    \left( \frac{z_{\vect{y}_i}- \mu(\vect{y}_i)}{\sigma(\vect{y}_i)} \right) \right]^{-1 / \xi(\vect{y}_i)} \right\}

defined on :math:`(\mu, \sigma, \xi)` such that :math:`1+\xi \left( \frac{z_{\vect{y}_i} -
\mu(\vect{y}_i)}{\sigma(\vect{y}_i)}\right) > 0` for all :math:`\vect{y}_i`.

And if any of the :math:`\xi(\vect{y}_i)` is equal to 0, the log-likelihood is defined as:

.. math::

    \ell (\vect{\beta}) = -\sum_{i=1}^{n} \left\{ \log(\sigma(\vect{y}_i)) + \frac{z_{\vect{y}_i} - \mu(\vect{y}_i)}{\sigma(\vect{y}_i)} + \exp \left\{ - \frac{z_{\vect{y}_i} - \mu(\vect{y}_i)}{\sigma(\vect{y}_i)} \right\} \right\}

The initialization of the optimization problem is crucial.
Two initial points :math:`(\mu_0, \sigma_0, \xi_0)` are proposed:

- the *Exponential* initial point: in that case, we assume that the GPD is a stationary
  Exponential distribution :math:`(\xi=0)` and we deduce
  :math:`\sigma_0` from the mean of the data: :math:`\sigma_0 = \dfrac{1}{n}
  \sum_{i=1}^n z_{\vect{y}_i}`;
- the *Static* initial point: in that case, we assume that the GPD is stationary and
  :math:`(\sigma_0, \xi_0)`
  is the maximum likelihood estimate resulting from that assumption.

The result class provides:

- the estimator :math:`\hat{\vect{\beta}}`,
- the asymptotic distribution of :math:`\hat{\vect{\beta}}`,
- the parameter functions :math:`\vect{y} \mapsto \vect{\theta}(\vect{y})`,
- the graphs of the parameter functions :math:`y_k \mapsto \theta_q(\vect{y})`, where all the components of
  :math:`\vect{y}` are fixed to a reference value excepted for :math:`y_k`, for each :math:`k`,
- the graphs of the parameter functions :math:`(y_k, y_\ell) \mapsto \theta_q(\vect{y})`, where all the
  components of :math:`\vect{y}` are fixed to a reference value excepted for
  :math:`(y_k, y_\ell)`, for each :math:`(k,\ell)`,
- the normalizing function :math:`(\tau_1, \dots, \tau_d)`,
- the optimal log-likelihood value :math:`\hat{\vect{\beta}}`,
- the GEV distribution at covariate :math:`\vect{y}`,
- the graphs of the quantile functions of order :math:`p`: :math:`y_k \mapsto q_p(Z_{\vect{y}})` where all
  the components of :math:`\vect{y}` are fixed to a reference value excepted for :math:`y_k`, for each :math:`k`,
- the graphs of the quantile functions of order :math:`p`: :math:`(y_k, y_\ell) \mapsto q_p(Z_{\vect{y}})` where
  all the components of :math:`\vect{y}` are fixed to a
  reference value excepted for :math:`(y_k, y_\ell)`, for each :math:`(k,\ell)`."

// ----------------------------------------------------------------------------

%feature("docstring") OT::GeneralizedParetoFactory::buildTimeVarying
"Estimate a non stationary GPD from a time-dependent parametric model.

Parameters
----------
sample : 2-d sequence of float
    Sample drawn from :math:`Z_t`.
u : float
    The threshold.
timeStamps : 2-d sequence of float
    Values of :math:`t`.
basis : :class:`~openturns.Basis`
    Functional basis.
sigmaIndices : sequence of int, optional
    Indices of basis terms considered for parameter :math:`\sigma`.
xiIndices : sequence of int, optional
    Indices of basis terms considered for parameter :math:`\xi`.
sigmaLink : :class:`~openturns.Function`, optional
    The :math:`h_{\sigma}` function.

    By default, the identity function.
xiLink : :class:`~openturns.Function`, optional
    The :math:`h_{\xi}` function.

    By default, the identity function.
initializationMethod : str, optional
    The initialization method for the optimization problem: *Gumbel* or *Static*.

    The default value depends on the key *GeneralizedExtremeValueFactory-InitializationMethod*.
normalizationMethod : str, optional
    The data normalization method: *CenterReduce*, *MinMax* or *None*.

    The default value depends on the key *GeneralizedExtremeValueFactory-NormalizationMethod*.

Returns
-------
result : :class:`~openturns.TimeVaryingResult`
    The result class.

Notes
-----
Let :math:`Z_t` be a non stationary random variable whose excesses above the threshold :math:`u` follow a GPD. We assume that :math:`u` is known:

.. math::

    Z_t \sim \mbox{GPD}(\sigma(t), \xi(t), u)

We denote by :math:`(z_{t_1}, \dots, z_{t_n})` the values of
:math:`Z_t` on the time stamps :math:`(t_1, \dots, t_n)`.

For numerical reasons, it is recommended to normalize the time stamps.
The following mapping is applied:

.. math::

    \tau(t) = \dfrac{t-c}{d}

and with three ways of defining :math:`(c,d)`:

- the *CenterReduce* method where :math:`c = \dfrac{1}{n} \sum_{i=1}^n t_i` is the mean
  time stamps
  and :math:`d = \sqrt{\dfrac{1}{n} \sum_{i=1}^n (t_i-c)^2}` is the standard deviation of the time stamps;
- the *MinMax* method where :math:`c = t_1` is the first time and :math:`d = t_n-t_1` the
  range of the time stamps;
- the *None* method where :math:`c = 0` and :math:`d = 1`: in that case, data are not
  normalized.


If we denote by :math:`\theta_q` is a component of :math:`\vect{\theta} = (\sigma, \xi)`,
then  :math:`\theta_q` can be written as a function of :math:`t`: 

.. math::

    \theta_q(t)  = h_q\left(\sum_{i=1}^{d_{\theta_q}} \beta_i^{\theta_q} \varphi_i^{\theta_q}
    (\tau(t))\right)

where:

- :math:`d_{\theta_q}` is the size of the functional basis involved in the modelling of
  :math:`\theta_q`,
- :math:`h_q: \Rset \mapsto \Rset` is usually referred to as the *inverse-link function* of
  the parameter :math:`\theta_q`,
- each :math:`\varphi_i^{\theta_q}` is a scalar function :math:`\Rset \mapsto \Rset`,
- each :math:`\beta_i^{j} \in \Rset`.

We denote by :math:`d_{\sigma}` and :math:`d_{\xi}` the size of the functional basis of
:math:`\sigma` and :math:`\xi` respectively. We denote by
:math:`\vect{\beta} = (\beta_1^{\sigma}, \dots, \beta_{d_{\sigma}}^{\sigma}, \beta_1^{\xi},
\dots, \beta_{d_{\xi}}^{\xi})` the complete vector of parameters.

The estimator of  :math:`\vect{\beta}` maximizes  the likelihood of the non stationary model which is defined by:

.. math::

    L(\vect{\beta}) = \prod_{i=1}^{n} g(z_{t_i};\sigma(t_i), \xi(t_i), u)

where :math:`g(z_{t};\sigma(t), \xi(t))` denotes the GPD density function with parameters
:math:`(\sigma(t), \xi(t), u)` evaluated at :math:`z_t`.

Then, if none of the :math:`\xi(t)` is zero, the log-likelihood is defined by:

.. math::

    \ell (\vect{\beta}) = -\sum_{i=1}^{n} \left\{ \log(\sigma(t_i)) + (1 + 1 / \xi(t_i) )
    \log\left[ 1+\xi(t_i) \left( \frac{z_{t_i} - \mu(t_i)}{\sigma(t_i)}\right) \right] + \left[ 1 +
    \xi(t_i) \left( \frac{z_{t_i}- \mu(t_i)}{\sigma(t_i)} \right) \right]^{-1 / \xi(t_i)} \right\}

defined on :math:`(\sigma, \xi, u)` such that :math:`1+\xi(t) \left( \frac{z_t - \mu(t)}{\sigma(t)}
\right) > 0` for all :math:`t`.

And if any of the :math:`\xi(t_i)` is equal to 0, the log-likelihood is defined as:

.. math::

    \ell (\vect{\beta}) = -\sum_{i=1}^{n} \left\{ \log(\sigma(t_i)) + \frac{z_{t_i} - \mu(t_i)}
    {\sigma(t_i)} + \exp \left\{ - \frac{z_{t_i} - \mu(t_i)}{\sigma(t_i)} \right\} \right\}

The initialization of the optimization problem is crucial.
Two initial points :math:`(\mu_0, \sigma_0, \xi_0)` are proposed:

- the *Exponential* initial point: in that case, we assume that the GPD is a stationary
  Exponential distribution :math:`(\xi=0)` and we deduce
  :math:`\sigma_0` from the mean of the data: :math:`\sigma_0 = \dfrac{1}{n}
  \sum_{i=1}^n z_{t_i}`;
- the *Static* initial point: in that case, we assume that the GPD is stationary and
  :math:`(\sigma_0, \xi_0)` is the maximum likelihood estimate resulting from that
  assumption.

The result class produced by the method provides:

- the estimator :math:`\hat{\vect{\beta}}`,
- the asymptotic distribution of :math:`\hat{\vect{\beta}}`,
- the parameter functions :math:`t \mapsto \vect{\theta}(t)`,
- the normalizing function :math:`t \mapsto \tau(t)`,
- the optimal log-likelihood value :math:`\hat{\vect{\beta}}`,
- the GPD distribution at time :math:`t`,
- the quantile functions of order :math:`p`: :math:`t \mapsto q_p(Z_t)`."

// ----------------------------------------------------------------------------

%feature("docstring") OT::GeneralizedParetoFactory::buildReturnLevelEstimator
"Estimate a return level and its distribution from the GPD parameters.

Parameters
----------
result : :class:`~openturns.DistributionFactoryResult`
    Likelihood estimation result obtained to estimate the GPD :math:`(\sigma, \xi, u)`.
sample : 2-d sequence of float
    The initial data from which the clusters (if any) have been extracted. If the data are independent, *sample* is the sample used to get *result*.
m : float
    The return period expressed in terms of number of observations.
theta : float, optional
    The extremal index defined in :eq:`defThetaZetaU`.
    
    Default value is 1.

Returns
-------
distribution : :class:`~openturns.Distribution`
    The asymptotic distribution of :math:`\hat{z}_m`.

Notes
-----
Let :math:`Z` a random variable whose excesses above the threshold
:math:`u` follow a Generalized Pareto distribution
:math:`GPD(\sigma, \xi)`. We assume that :math:`u` is known.

The :math:`m`-observation return level :math:`z_m` is the level exceeded on
average once every :math:`m` observations.
The :math:`m`-observation return level can be translated into the annual-scale: if there
are :math:`n_y` observations per year, then the :math:`N`-year return level
corresponds to the :math:`m`-observation return level where :math:`m = n_yN`.

The :math:`m`-observation return level is defined as a particular quantile of :math:`Z`:

If :math:`\xi \neq 0`:

.. math::
    :label: xm1gpd

    z_m = u + \frac{\sigma}{\xi}\left[(m \zeta_u \theta)^{\xi} - 1 \right]

If :math:`\xi = 0`:

.. math::
    :label: xm2gpd

    z_m = u + \sigma \log(m \zeta_u \theta)

with :math:`\zeta_u` the probability of an exceedance of :math:`u`
and :math:`\theta` the extremal index. Denoting the number of observations by
:math:`n`, the number of  exceedances of the threshold :math:`u` by
:math:`n_u` and the number of clusters obtained above :math:`u` by
:math:`n_c`, then :math:`\zeta_u` and :math:`\theta` are estimated by:

.. math::
    :label: defThetaZetaU

    \zeta_u & = \dfrac{n_u}{n}\\
    \theta  & = \dfrac{n_c}{n_u}

If the data are independent, no clustering is performed and :math:`\theta=1`.

The estimator :math:`\hat{z}_m` of :math:`z_m` is deduced from the estimator
:math:`(\hat{\sigma}, \hat{\xi}, \hat{\zeta_u})` of :math:`(\sigma, \xi, \zeta_u)`
of the GPD.

The asymptotic distribution of :math:`\hat{z}_m` is obtained by the Delta method from the asymptotic distribution of
:math:`(\hat{\sigma}, \hat{\xi}, \hat{\zeta}_u)`. It is a normal distribution with mean :math:`\hat{z}_m` and variance:

.. math::

    \Var{\hat{z}_m} = (\nabla z_m)^T \mat{V}_n \nabla z_m

where :math:`\nabla z_m = (\frac{\partial z_m}{\partial \mu}, \frac{\partial z_m}{\partial \sigma}, \frac{\partial z_m}{\partial \xi})`
and :math:`\mat{V}_n` is the asymptotic covariance of :math:`(\hat{\sigma}, \hat{\xi}, \hat{\mu})`."

// ----------------------------------------------------------------------------

%feature("docstring") OT::GeneralizedParetoFactory::buildReturnLevelProfileLikelihoodEstimator
"Estimate :math:`(z_m, \xi)` and its distribution with the profile likelihood.

Parameters
----------
sample : 2-d sequence of float
    A sample of dimension 1.
u : float
    The threshold.
m : float
    The return period expressed in terms of number of observations.
theta : float, optional
    When clustering is performed, this is the ratio :math:`\theta = \frac{n_c}{n_u}` of number
    of clusters over number of exceedances, otherwise defaults to 1.

Returns
-------
result : :class:`~openturns.ProfileLikelihoodResult`
    The result class.

Notes
-----
Let :math:`Z` a random variable whose excesses above the threshold
:math:`u` follow a Generalized Pareto distribution
:math:`GPD(\sigma, \xi)`. We assume that :math:`u` is known.

The return level :math:`z_m` is defined in :meth:`buildReturnLevelEstimator`. The profile log-likelihood :math:`\ell_p(z_m)` is defined in
:meth:`buildReturnLevelProfileLikelihood`.

The result class produced by the method provides:

- the GPD distribution associated to :math:`(\hat{z}_m, \hat{\xi}, u)`,
- the asymptotic distribution of :math:`(\hat{z}_m, \hat{\xi}, u)`,
- the profile log-likelihood function :math:`z_m \mapsto \ell_p(z_m)`,
- the optimal profile log-likelihood value :math:`\ell_p(\hat{z}_m)`,
- confidence intervals of level :math:`(1-\alpha)` of :math:`\hat{z}_m`."

// ----------------------------------------------------------------------------

%feature("docstring") OT::GeneralizedParetoFactory::buildReturnLevelProfileLikelihood
"Estimate a return level and its distribution with the profile likelihood.

Parameters
----------
sample : 2-d sequence of float
    A sample of dimension 1.
u : float
    The threshold.
m : float
    The return period expressed in terms of number of observations.
theta : float, optional
    The extremal index defined in :eq:`defThetaZetaU`.
    
    Default value is 1.

Returns
-------
distribution : :class:`~openturns.Normal`
    The asymptotic distribution of :math:`\hat{z}_m`.

Notes
-----
Let :math:`Z` a random variable whose excesses above the threshold
:math:`u` follow a Generalized Pareto distribution
:math:`GPD(\sigma, \xi)`. We assume that :math:`u` is known.

The return level :math:`z_m` is defined in :meth:`buildReturnLevelEstimator`.

The estimator :math:`\hat{z}_m` of :math:`z_m` is defined using a nested numerical optimization of the log-likelihood:

.. math::

    \ell_p (z_m) = \max_{\xi} \ell (z_m, \xi, u)

where :math:`\ell (z_m, \xi, u)` is the log-likelihood detailed in :eq:`llgpdR1` and :eq:`llgpdR2`
where we substitued
:math:`\sigma` for :math:`z_m` using equations :eq:`xm1gpd` or :eq:`xm2gpd`.

Then :math:`\hat{z}_m` is defined by:

.. math::

    \hat{z}_m = \argmax_{z_m} \ell_p(z_m)

The asymptotic distribution of :math:`\hat{z}_m` is normal.

The starting point of the optimization is initialized from the regular maximum likelihood method."
