%feature("docstring") OT::GeneralizedLinearModelAlgorithm
"Algorithm for the evaluation of general linear models.

Available constructors:
    GeneralizedLinearModelAlgorithm(*inputSample, outputSample, covarianceModel, basis, normalize=True, keepCovariance=True*)

    GeneralizedLinearModelAlgorithm(*inputSample, inputTransformation, outputSample, covarianceModel, basis, keepCovariance=True*)

    GeneralizedLinearModelAlgorithm(*inputSample, outputSample, covarianceModel, multivariateBasis, normalize=True, keepCovariance=True*)

    GeneralizedLinearModelAlgorithm(*inputSample, inputTransformation, outputSample, covarianceModel, multivariateBasis, keepCovariance=True*)

Parameters
----------
inputSample, outputSample : :class:`~openturns.NumericalSample` or 2d-array
    The samples :math:`(\vect{x}_k)_{1 \leq k \leq N} \in \Rset^d` and :math:`(\vect{y}_k)_{1 \leq k \leq N}\in \Rset^p`.
inputTransformation : :class:`~openturns.NumericalMathFunction`
    Function  *T* that helps to normalize the input sample.

    If used, the meta model is built on the transformed data.
basis : :class:`~openturns.Basis`
    Functional basis to estimate the trend: :math:`(\varphi_j)_{1 \leq j \leq n_1}: \Rset^d \rightarrow \Rset`. 

    If :math:`p>1`, the same basis is used for each marginal output.
multivariateBasis : collection of :class:`~openturns.Basis`
    Collection of :math:`p` functional basis: one basis for each marginal output.

    If the trend is not estimated, the collection must be empty.
covarianceModel : :class:`~openturns.CovarianceModel`
    Covariance model of the normal process. 
normalize : bool, optional
    Indicates whether the input sample has to be normalized.

    It uses the transformation fixed by the User in *inputTransformation* or the empirical mean and variance of the input sample.
    Default is set in resource map key `GeneralizedLinearModelAlgorithm-NormalizeData`
keepCovariance : bool, optional
    Indicates whether the covariance matrix has to be stored in the result structure *GeneralizedLinearModelResult*.
    Default is set in resource map key `GeneralizedLinearModelAlgorithm-KeepCovariance`

Notes
-----
We suppose we have a sample :math:`(\vect{x}_k, \vect{y}_k)_{1 \leq k \leq N}` where :math:`\vect{y}_k = \cM(\vect{x}_k)` for all *k*, with :math:`\cM:\Rset^d \mapsto \Rset^p` the model.

The objective is to build a metamodel :math:`\tilde{\cM}`, using a **generalized linear model**: the sample :math:`(\vect{y}_k)_{1 \leq k \leq N}` is considered as the trace of a normal process :math:`\vect{Y}(\omega, \vect{x})` on :math:`(\vect{x}_k)_{1 \leq k \leq N}`. The normal process :math:`\vect{Y}(\omega, \vect{x})` is defined by:

.. math::

    \vect{Y}(\omega, \vect{x}) = \vect{\mu}(\vect{x}) + \vect{W}(\omega, \vect{x})

where:

.. math::

    \vect{\mu}(\vect{x}) = \left(
      \begin{array}{l}
        \mu_1(\vect{x}) \\
        \dots  \\
        \mu_p(\vect{x}) 
       \end{array}
     \right)

with :math:`\mu_l(\vect{x}) = \sum_{j=1}^{n_l} \alpha_j^l \varphi_j^l(\vect{x})` and :math:`\varphi_j^l: \Rset^d \rightarrow \Rset` the trend functions.

:math:`\vect{W}` is a normal process of dimension *p* with zero mean and covariance function :math:`C = C(\vect{\theta}, \vect{\sigma}, \mat{R}, \vect{\lambda})` (see :class:`~openturns.CovarianceModel` for the notations).

We note:

.. math::

    \vect{\alpha}^l(\vect{x}) = \left(
      \begin{array}{l}
        \alpha_1^l \\
        \dots  \\
        \alpha_{n_l}^l
       \end{array}
     \right) \in \Rset^{n_l}
     \quad \mbox{ and } \quad 
     \vect{\alpha}(\vect{x}) = \left(
      \begin{array}{l}
         \vect{\alpha}^1\\
        \dots  \\
         \vect{\alpha}^p
       \end{array}
     \right)\in \Rset^{\sum_{l=1}^p n_l}


The *GeneralizedLinearModelAlgorithm* class estimates the coefficients :math:`\alpha_j^l, \vect{\theta}, \vect{\sigma}` by maximizing the likelihood of the model. The values of :math:`(\vect{\theta}, \vect{\sigma})` fixed by the User at the creation of the class are used as initial values for the optimization algorithm.

Note that the parameters :math:`(\mat{R}, \vect{\lambda})` are not optimized: they are fixed to the values specified by the User.

If a normalizing transformation *T* has been used, the meta model is bilt on the inputs :math:`\vect{z}_k = T(\vect{x}_k)`.

 **Estimation of the parameters** :math:`\alpha_j^l, \vect{\theta}, \vect{\sigma}`

We note:

.. math::

    \vect{y} = \left(
      \begin{array}{l}
        \vect{y}_1 \\
        \dots  \\
        \vect{y}_N
       \end{array}
     \right) \in \Rset^{pN},
     \quad 
     \vect{m} = \left(
      \begin{array}{l}
        \vect{\mu}(\vect{x}_1) \\
        \dots  \\
        \vect{\mu}(\vect{x}_N)
       \end{array}
     \right) \in \Rset^{pN}

 and 

.. math::

    \mat{C} = \left(
      \begin{array}{lcl}
        \mat{C}_{11} & \dots &  \mat{C}_{1N}\\
        \dots & \dots & \\
        \mat{C}_{N1} & \dots &  \mat{C}_{NN}
       \end{array}
     \right) \in \cS_{pN}^+(\Rset)

where :math:`\mat{C}_{ij} = C(\vect{x}_i, \vect{x}_j)`. 

The model likelihood writes:

.. math::

    p((\vect{x}_k, \vect{y}_k)_{1 \leq k \leq N}) = \dfrac{1}{(2\pi)^{pN/2} |\det \mat{C}|^{1/2}} \exp\left[ -\dfrac{1}{2}\Tr{\left( \vect{y}-\vect{m} \right)} \mat{C}^{-1}  \left( \vect{y}-\vect{m} \right)  \right]

With  :math:`\mat{L}` the inferior triangular matrix such that :math:`\mat{L}\Tr{\mat{L}} = \mat{C}`, then:

.. math::
    :label: logLikelihood

    \log p((\vect{x}_k, \vect{y}_k)_{1 \leq k \leq N}) = cste -\dfrac{1}{2} \log \det \mat{L} -\dfrac{1}{2}  \| \mat{L}^{-1}(\vect{y}-\vect{m}) \|^2

It proceeds as follows:

    - maximization of :eq:`logLikelihood` with respect to :math:`\vect{\alpha}` where :math:`(\vect{\theta}, \vect{\sigma})` are fixed: it is equivalent to minimizing the term :math:`\| \mat{L}^{-1}(\vect{y}-\vect{m}) \|^2` (the optimization problem is a least square problem). Then :math:`\vect{\alpha} = \vect{\alpha}(\vect{\theta}, \vect{\sigma})`;
    - maximization of :eq:`logLikelihood` with respect to :math:`\vect{\theta}, \vect{\sigma}` where :math:`\vect{\alpha}` has been replaced by  :math:`\vect{\alpha} = \vect{\alpha}(\vect{\theta}, \vect{\sigma})`. 
    - then, we obtain the optimal values :math:`(\vect{\theta}^*, \vect{\sigma}^*)`  and :math:`\vect{\theta}^* = \vect{\alpha}(\vect{\theta}^*, \vect{\sigma}^*)`.

In the particular case where :math:`p=1`, the first step introduces the additional relation :math:`\vect{\sigma} = \vect{\sigma}(\vect{\theta})`. Thus, the second step is optimized with respect to the only parameter :math:`\vect{\theta}` and the optimized values write :math:`\vect{\sigma}^* = \vect{\sigma}(\vect{\theta}^*)` and :math:`\vect{\alpha}^* = \vect{\alpha}(\vect{\theta}^*)`.


Default optimizer is :class:`~openturns.TNC` and can be changed thanks to the *setOptimizationSolver* method. User could also change the default optimization solver by setting the `GeneralizedLinearModelAlgorithm-DefaultOptimizationSolver` resource map key to `NELDER-MEAD` or `LBFGS` respectively for Nelder-Mead and LBFGS-B solvers.

It is also possible to proceed as follows:

    - ask for the log-likelihood function of the *GeneralizedLinearModelAlgorithm* thanks to the *getObjectiveFunction()* method
    - optimize it with respect to the parameters :math:`\vect{\theta}` and  :math:`\vect{\sigma}` using any optimisation algorithms (that can take into account some additional constraints if needed)
    - fulfill the *GeneralizedLinearModelAlgorithm* with the optimized value of these parameters.


With huge samples, the `hierarchical matrix <http://en.wikipedia.org/wiki/Hierarchical_matrix>`_  implementation could be used if the library had been compiled with `hmat-oss` support.

This implementation, which is based on a sparse representation of an approximated covariance matrix (and its Cholesky factor), has a better complexity both in terms of memory requirements and floating point operations. To use it, the `GeneralizedLinearModelAlgorithm-LinearAlgebra` resource map key should be instancied to `HMAT`. Default value of the key is `LAPACK`.

Examples
--------
Create the model :math:`\cM: \Rset \mapsto \Rset` and the samples:

>>> import openturns as ot
>>> f = ot.NumericalMathFunction(['x'], ['x * sin(x)'])
>>> inputSample = ot.NumericalSample([[1.0], [3.0], [5.0], [6.0], [7.0], [8.0]])
>>> outputSample = f(inputSample)

Create the algorithm:

>>> basis = ot.ConstantBasisFactory().build()
>>> covarianceModel = ot.SquaredExponential(1)
>>> algo = ot.GeneralizedLinearModelAlgorithm(inputSample, outputSample, covarianceModel, basis)
>>> algo.run()

Get the resulting meta model:

>>> result = algo.getResult()
>>> metamodel = result.getMetaModel()"

// ---------------------------------------------------------------------

%feature("docstring") OT::GeneralizedLinearModelAlgorithm::getInputTransformation
"Get the function normalizing the input.

Returns
-------
transformation : :class:`~openturns.NumericalMathFunction`
    Function *T* that normalizes the input."

// ---------------------------------------------------------------------

%feature("docstring") OT::GeneralizedLinearModelAlgorithm::setInputTransformation
"Set the function normalizing the input.

Parameters
----------
transformation : :class:`~openturns.NumericalMathFunction`
    Function that normalizes the input.
    The input dimension should be the same as input's sample dimension, output dimension
    should be output sample's dimension"

// ---------------------------------------------------------------------

%feature("docstring") OT::GeneralizedLinearModelAlgorithm::getResult
"Get the results of the metamodel computation.

Returns
-------
result : :class:`~openturns.GeneralizedLinearModelResult`
    Structure containing all the results obtained after computation
    and created by the method :py:meth:`run`.
"

//-----------------------------------------------------------------------

%feature("docstring") OT::GeneralizedLinearModelAlgorithm::getInputSample
"Accessor to the input sample.

Returns
-------
inputSample : :class:`~openturns.NumericalSample`
    The input sample :math:`(\vect{x}_k)_{1 \leq k \leq N}`."

// ---------------------------------------------------------------------

%feature("docstring") OT::GeneralizedLinearModelAlgorithm::getOutputSample
"Accessor to the output sample.

Returns
-------
outputSample : :class:`~openturns.NumericalSample`
    The output sample :math:`(\vect{y}_k)_{1 \leq k \leq N}` ."

// ---------------------------------------------------------------------

%feature("docstring") OT::GeneralizedLinearModelAlgorithm::getObjectiveFunction()
"Accessor to the log-likelihood function that writes as argument of the covariance's model parameters.

Returns
-------
logLikelihood : :class:`~openturns.NumericalMathFunction`
    The log-likelihood function degined in :eq:`logLikelihood` as a function of :math:`(\vect{\theta}, \vect{\sigma})`.

Notes
-----
The log-likelihood function may be useful for some postprocessing: maximization using external optimizers for example.


Examples
--------
Create the model :math:`\cM: \Rset \mapsto \Rset` and the samples:

>>> import openturns as ot
>>> f = ot.NumericalMathFunction(['x0'], ['f0'], ['x0 * sin(x0)'])
>>> inputSample = ot.NumericalSample([[1.0], [3.0], [5.0], [6.0], [7.0], [8.0]])
>>> outputSample = f(inputSample)

Create the algorithm:

>>> basis = ot.ConstantBasisFactory().build()
>>> covarianceModel = ot.SquaredExponential(1)
>>> algo = ot.GeneralizedLinearModelAlgorithm(inputSample, outputSample, covarianceModel, basis)
>>> algo.run()

Get the log-likelihood function:

>>> likelihoodFunction = algo.getObjectiveFunction()
"


// ---------------------------------------------------------------------

%feature("docstring") OT::GeneralizedLinearModelAlgorithm::run
"Compute the response surface.

Notes
-----
It computes the response surface and creates a
:class:`~openturns.GeneralizedLinearModelResult` structure containing all the results."

// ---------------------------------------------------------------------

%feature("docstring") OT::GeneralizedLinearModelAlgorithm::getOptimizationSolver
"Accessor to solver used to optimize the covariance model parameters.

Returns
-------
algorithm : :class:`~openturns.OptimizationSolver`
    Solver used to optimize the covariance model parameters.
    Default optimizer is :class:`~openturns.TNC`"

// ---------------------------------------------------------------------

%feature("docstring") OT::GeneralizedLinearModelAlgorithm::setOptimizationSolver
"Accessor to the solver used to optimize the covariance model parameters.

Parameters
----------
algorithm : :class:`~openturns.OptimizationSolver`
    Solver used to optimize the covariance model parameters."

// ---------------------------------------------------------------------

%feature("docstring") OT::GeneralizedLinearModelAlgorithm::setOptimizeParameters
"Covariance model parameters optimization flag accessor.

Parameters
----------
optimizeParams : bool
    Whether to optimize the covariance model parameters."

// ---------------------------------------------------------------------

%feature("docstring") OT::GeneralizedLinearModelAlgorithm::getOptimizeParameters
"Covariance model parameters optimization flag accessor.

Returns
-------
optimizeParams : bool
    Whether to optimize the covariance model parameters."

