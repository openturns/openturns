{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration of the flooding model with linear least squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this example is to calibrate the simulator associated with the flooding model with linear least squares. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openturns as ot\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by reading the observations from the data file. There are 100 observations of the couple (Q,H)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observedSample = ot.Sample_ImportFromCSVFile(\"calibration-flooding-observations.csv\")\n",
    "nbobs = observedSample.getSize()\n",
    "Qobs = observedSample[:,0]\n",
    "Hobs = observedSample[:,1]\n",
    "nbobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hobs.setDescription([\"Height (m)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the model which has 4 inputs and one output H."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def functionFloodingModel(X):\n",
    "    Q, K_s, Z_v, Z_m = X\n",
    "    L = 5.0e3\n",
    "    B = 300.0\n",
    "    alpha = (Z_m - Z_v)/L\n",
    "    H = (Q/(K_s*B*np.sqrt(alpha)))**(3.0/5.0)\n",
    "    return [H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPyFunc = ot.PythonFunction(4, 1, functionFloodingModel)\n",
    "modelPyFunc.setDescription([\"Q\", \"Ks\", \"Zv\", \"Zm\",\"H\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the value of the reference values of the $\\theta$ parameter. In the bayesian framework, this is called the mean of the *prior* gaussian distribution. In the data assimilation framework, this is called the *background*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "KsInitial = 20.\n",
    "ZvInitial = 49.\n",
    "ZmInitial = 51.\n",
    "thetaBackground = ot.Point([KsInitial,ZvInitial,ZmInitial])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following statement create the calibrated function from the model. The calibrated parameters Ks, Zv, Zm are at indices 1, 2, 3 in the inputs arguments of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calibratedIndices = [1,2,3]\n",
    "mycf = ot.ParametricFunction(modelPyFunc, calibratedIndices, thetaBackground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CalibrationGraphics as cg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defined the covariance matrix of the parameters $\\theta$ to calibrate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `LinearLeastSquaresCalibration` class performs the linear least squares calibration by linearizing the model in the neighbourhood of the reference point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = ot.LinearLeastSquaresCalibration(mycf, Qobs, Hobs, thetaBackground,\"SVD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `run` method computes the solution of the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrationResult = algo.getResult()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `getParameterMAP` method returns the maximum of the posterior distribution of $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>[-2.76461e+06,2.10196e+06,2.65489e+06]</p>"
      ],
      "text/plain": [
       "class=Point name=Unnamed dimension=3 values=[-2.76461e+06,2.10196e+06,2.65489e+06]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thetaStar = calibrationResult.getParameterMAP()\n",
    "thetaStar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we see that there seems to be a great distance from the reference value of $\\theta$ to the optimum: the values seem too large in magnitude. The value of the optimum $K_s$ is nonpositive. In fact, there is an identification problem because the Jacobian matrix is rank-degenerate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostic of the identification issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we show how to diagnose the identification problem.\n",
    "\n",
    "The `getParameterPosterior` method returns the posterior gaussian distribution of $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Normal(mu = [-2.76461e+06,2.10196e+06,2.65489e+06], sigma = [3.75019e+06,2.04034e+06,2.49625e+06], R = [[  1        -0.491947 -0.702566 ]<br>\n",
       " [ -0.491947  1         0.965178 ]<br>\n",
       " [ -0.702566  0.965178  1        ]])</p>"
      ],
      "text/plain": [
       "class=Normal name=Normal dimension=3 mean=class=Point name=Unnamed dimension=3 values=[-2.76461e+06,2.10196e+06,2.65489e+06] sigma=class=Point name=Unnamed dimension=3 values=[3.75019e+06,2.04034e+06,2.49625e+06] correlationMatrix=class=CorrelationMatrix dimension=3 implementation=class=MatrixImplementation name=Unnamed rows=3 columns=3 values=[1,-0.491947,-0.702566,-0.491947,1,0.965178,-0.702566,0.965178,1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distributionPosterior = calibrationResult.getParameterPosterior()\n",
    "distributionPosterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is a large covariance matrix diagonal. \n",
    "\n",
    "Let us compute a 95% confidence interval for the solution $\\theta^\\star$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>[-3.14559e+07, 2.59267e+07]<br>\n",
       "[-1.3508e+07, 1.77119e+07]<br>\n",
       "[-1.6443e+07, 2.17527e+07]</p>"
      ],
      "text/plain": [
       "class=Interval name=Unnamed dimension=3 lower bound=class=Point name=Unnamed dimension=3 values=[-3.14559e+07,-1.3508e+07,-1.6443e+07] upper bound=class=Point name=Unnamed dimension=3 values=[2.59267e+07,1.77119e+07,2.17527e+07] finite lower bound=[1,1,1] finite upper bound=[1,1,1]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distributionPosterior.computeBilateralConfidenceIntervalWithMarginalProbability(0.95)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confidence interval is *very* large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycf.setParameter(thetaBackground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetaDim = thetaBackground.getDimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>5x3<br>\n",
       "[[ -0.107544  0.537722 -0.537722 ]<br>\n",
       " [ -0.142996  0.71498  -0.714979 ]<br>\n",
       " [ -0.13431   0.671551 -0.671551 ]<br>\n",
       " [ -0.166852  0.834258 -0.834258 ]<br>\n",
       " [ -0.118782  0.593908 -0.593908 ]]</p>"
      ],
      "text/plain": [
       "class=Matrix implementation=class=MatrixImplementation name=Unnamed rows=5 columns=3 values=[-0.107544,-0.142996,-0.13431,-0.166852,-0.118782,0.537722,0.71498,0.671551,0.834258,0.593908,-0.537722,-0.714979,-0.671551,-0.834258,-0.593908]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobianMatrix = ot.Matrix(nbobs,thetaDim)\n",
    "for i in range(nbobs):\n",
    "    jacobianMatrix[i,:] = mycf.parameterGradient(Qobs[i]).transpose()\n",
    "jacobianMatrix[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>[8.93138,4.74722e-08,2.26851e-08]</p>"
      ],
      "text/plain": [
       "class=Point name=Unnamed dimension=3 values=[8.93138,4.74722e-08,2.26851e-08]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobianMatrix.computeSingularValues()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the singular values associated with $Z_v$ and $Z_m$ are relatively close to zero, compared to the singular value associated with $K_s$. \n",
    "\n",
    "This explains why the Jacobian matrix is close to being rank-degenerate.\n",
    "\n",
    "In other words, the value of $K_s$ can be calibrated, but not $Z_v$ or $Z_m$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several methods to solve the problem.\n",
    "* Given that the problem is not identifiable, we can use some regularization method. Two methods are provided in the library: the gaussian linear least squares `BLUE` and the gaussian non linear least squares `ThreeDVar'.\n",
    "* We can change the problem, replacing it with a problem which is identifiable. In the flooding model, replacing $Z_v-Z_m$ with $\\Delta Z$ allows to solve the issue."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
